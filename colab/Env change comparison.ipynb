{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f10d84c-a220-4ba0-8fb1-fc6d85e59985",
   "metadata": {},
   "source": [
    "# Comparison Example for OSAR, DQN and C51 agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ee78e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /mnt/c/Users/ustyu/OneDrive/Projects/OSAR-keras\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from OSAR-nightly==0.1.17.dev20220302) (4.8.2)\n",
      "Requirement already satisfied: gin-config>=0.5.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from OSAR-nightly==0.1.17.dev20220302) (0.5.0)\n",
      "Requirement already satisfied: atari_py>=0.2.9 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from OSAR-nightly==0.1.17.dev20220302) (0.2.9)\n",
      "Requirement already satisfied: dm-reverb[tensorflow]>=0.6.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from OSAR-nightly==0.1.17.dev20220302) (0.6.1)\n",
      "Requirement already satisfied: gym[atari]>=0.21.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from OSAR-nightly==0.1.17.dev20220302) (0.21.0)\n",
      "Requirement already satisfied: tf-agents[reverb]>=0.11.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from OSAR-nightly==0.1.17.dev20220302) (0.11.0)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from OSAR-nightly==0.1.17.dev20220302) (4.62.3)\n",
      "Requirement already satisfied: imageio>=2.8.2 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from OSAR-nightly==0.1.17.dev20220302) (2.11.0)\n",
      "Requirement already satisfied: PILLOW>=7.1.2 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from OSAR-nightly==0.1.17.dev20220302) (8.4.0)\n",
      "Requirement already satisfied: pandas>=1.3.4 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from OSAR-nightly==0.1.17.dev20220302) (1.3.4)\n",
      "Requirement already satisfied: pybullet>=3.2.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from OSAR-nightly==0.1.17.dev20220302) (3.2.0)\n",
      "Requirement already satisfied: six in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from atari_py>=0.2.9->OSAR-nightly==0.1.17.dev20220302) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from atari_py>=0.2.9->OSAR-nightly==0.1.17.dev20220302) (1.21.4)\n",
      "Requirement already satisfied: dm-tree in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (0.1.6)\n",
      "Requirement already satisfied: portpicker in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (1.5.0)\n",
      "Requirement already satisfied: tensorflow~=2.7.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (2.7.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from gym[atari]>=0.21.0->OSAR-nightly==0.1.17.dev20220302) (2.0.0)\n",
      "Requirement already satisfied: ale-py~=0.7.1 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from gym[atari]>=0.21.0->OSAR-nightly==0.1.17.dev20220302) (0.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from pandas>=1.3.4->OSAR-nightly==0.1.17.dev20220302) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from pandas>=1.3.4->OSAR-nightly==0.1.17.dev20220302) (2021.3)\n",
      "Requirement already satisfied: tensorflow-probability>=0.14.1 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tf-agents[reverb]>=0.11.0->OSAR-nightly==0.1.17.dev20220302) (0.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tf-agents[reverb]>=0.11.0->OSAR-nightly==0.1.17.dev20220302) (1.13.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tf-agents[reverb]>=0.11.0->OSAR-nightly==0.1.17.dev20220302) (4.0.0)\n",
      "Requirement already satisfied: protobuf>=3.11.3 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tf-agents[reverb]>=0.11.0->OSAR-nightly==0.1.17.dev20220302) (3.19.1)\n",
      "Requirement already satisfied: absl-py>=0.6.1 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tf-agents[reverb]>=0.11.0->OSAR-nightly==0.1.17.dev20220302) (1.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from importlib-metadata->OSAR-nightly==0.1.17.dev20220302) (3.6.0)\n",
      "Requirement already satisfied: importlib-resources in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from ale-py~=0.7.1->gym[atari]>=0.21.0->OSAR-nightly==0.1.17.dev20220302) (5.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (3.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (1.42.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (2.7.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (1.1.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (12.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (0.37.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (3.3.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (2.7.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (0.22.0)\n",
      "Requirement already satisfied: decorator in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorflow-probability>=0.14.1->tf-agents[reverb]>=0.11.0->OSAR-nightly==0.1.17.dev20220302) (5.1.0)\n",
      "Requirement already satisfied: psutil in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from portpicker->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (5.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (2.0.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (59.1.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (1.8.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (2.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (1.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (2021.10.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.7.0->dm-reverb[tensorflow]>=0.6.0->OSAR-nightly==0.1.17.dev20220302) (3.1.1)\n",
      "Building wheels for collected packages: OSAR-nightly\n",
      "  Building wheel for OSAR-nightly (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for OSAR-nightly: filename=OSAR_nightly-0.1.17.dev20220302-cp39-cp39-linux_x86_64.whl size=47907 sha256=53fcfcee5cc40f7635f3ba17528ce93ccd07c1a69eff74084f98d437c18de637\n",
      "  Stored in directory: /home/constantine/.cache/pip/wheels/b0/55/4a/1bb4852a26744ba9735d506993c618d1ab7be56275314d8ea7\n",
      "Successfully built OSAR-nightly\n",
      "Installing collected packages: OSAR-nightly\n",
      "  Attempting uninstall: OSAR-nightly\n",
      "    Found existing installation: OSAR-nightly 0.1.17.dev20220302\n",
      "    Uninstalling OSAR-nightly-0.1.17.dev20220302:\n",
      "      Successfully uninstalled OSAR-nightly-0.1.17.dev20220302\n",
      "Successfully installed OSAR-nightly-0.1.17.dev20220302\n"
     ]
    }
   ],
   "source": [
    "!pip install ../../OSAR-keras/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hispanic-twelve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 23:19:27.888334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-02 23:19:27.905843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-02 23:19:27.906447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-02 23:19:27.907766: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-02 23:19:27.908624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-02 23:19:27.908991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-02 23:19:27.909295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-02 23:19:28.610327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-02 23:19:28.610748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-02 23:19:28.610763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-03-02 23:19:28.611075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-02 23:19:28.611161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1615 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents import agents\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n",
    "import pyvirtualdisplay\n",
    "\n",
    "from OSAR import OSARQNetwork, Runner, DQNTrialAgent\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb789839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sufficient-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 1000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 1  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 20  # @param {type:\"integer\"}\n",
    "memory_len = 10 # @param {type: \"integer\"}\n",
    "n_turns = 3 # @param {type: \"integer\"}\n",
    "num_atoms = 51  # @param {type:\"integer\"}\n",
    "q_value = 20  # @param {type:\"integer\"}\n",
    "n_step_update = 2  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}\n",
    "\n",
    "boltzmann_temperature = 10e-5 # @param {type:\"float\"}\n",
    "epsilon_greedy = None # @param {type:\"float\"}\n",
    "conv_type = '2d' # @param {type:\"str\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e7da49-b335-47e2-87be-215043291e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (10, 10)\n",
    "from tf_agents.networks import q_network\n",
    "\n",
    "osar_specs = {\n",
    "    'batch_size': batch_size,\n",
    "    'memory_len': memory_len,\n",
    "    'n_turns': n_turns,\n",
    "    'fc_layer_params': fc_layer_params,\n",
    "    'num_atoms': num_atoms,\n",
    "    'conv_type': conv_type,\n",
    "    'learning_rate': learning_rate,\n",
    "    'q_value': q_value,\n",
    "    'n_step_update': n_step_update,\n",
    "    'boltzmann_temperature': boltzmann_temperature,\n",
    "    'epsilon_greedy': epsilon_greedy,\n",
    "    'debug_summaries': True,\n",
    "    'summarize_grads_and_vars': True,\n",
    "}\n",
    "\n",
    "def osar_generator(\n",
    "    observation_spec,\n",
    "    action_spec,\n",
    "    batch_size,\n",
    "    memory_len,\n",
    "    n_turns,\n",
    "    fc_layer_params,\n",
    "    num_atoms,\n",
    "    conv_type,\n",
    "    learning_rate,\n",
    "    time_step_spec,\n",
    "    n_step_update=2,\n",
    "    train_step_counter=tf.Variable(0, dtype=tf.int64),\n",
    "    q_value=q_value,\n",
    "    boltzmann_temperature=None,\n",
    "    epsilon_greedy=0.1,\n",
    "    debug_summaries=True,\n",
    "    summarize_grads_and_vars=True,\n",
    "    **kwargs,\n",
    "    ):\n",
    "    q_net = OSARQNetwork(\n",
    "        observation_spec,\n",
    "        action_spec,\n",
    "        batch_size,\n",
    "        memory_len,\n",
    "        n_turns,\n",
    "        fc_layer_params=fc_layer_params,\n",
    "        conv_type=conv_type,\n",
    "        )\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    agent = DQNTrialAgent(\n",
    "        time_step_spec,\n",
    "        action_spec,\n",
    "        network=q_net,\n",
    "        optimizer=optimizer,\n",
    "        td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "        boltzmann_temperature=boltzmann_temperature,\n",
    "        epsilon_greedy=epsilon_greedy,\n",
    "        debug_summaries=debug_summaries,\n",
    "        train_step_counter = train_step_counter,\n",
    "        summarize_grads_and_vars=summarize_grads_and_vars,\n",
    "    )\n",
    "    \n",
    "    agent.initialize()\n",
    "    \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b7a91f2-bd38-4702-831c-a6955ccf0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (64, 64)\n",
    "from tf_agents.networks import categorical_q_network\n",
    "\n",
    "c51_specs = {\n",
    "    'batch_size': batch_size,\n",
    "    'memory_len': memory_len,\n",
    "    'fc_layer_params': fc_layer_params,\n",
    "    'num_atoms': num_atoms,\n",
    "    'conv_type': conv_type,\n",
    "    'learning_rate': learning_rate,\n",
    "    'q_value': q_value,\n",
    "    'n_step_update': n_step_update,\n",
    "    'boltzmann_temperature': boltzmann_temperature,\n",
    "    'epsilon_greedy': epsilon_greedy,\n",
    "    'debug_summaries': True,\n",
    "    'summarize_grads_and_vars': True,\n",
    "}\n",
    "def c51_generator(\n",
    "    observation_spec,\n",
    "    action_spec,\n",
    "    batch_size,\n",
    "    memory_len,\n",
    "    fc_layer_params,\n",
    "    num_atoms,\n",
    "    learning_rate,\n",
    "    time_step_spec,\n",
    "    n_step_update=2,\n",
    "    conv_type='2d',\n",
    "    train_step_counter=tf.Variable(0, dtype=tf.int64),\n",
    "    q_value=q_value,\n",
    "    boltzmann_temperature=None,\n",
    "    epsilon_greedy=0.1,\n",
    "    debug_summaries=True,\n",
    "    summarize_grads_and_vars=True,\n",
    "    ):\n",
    "\n",
    "    q_net = categorical_q_network.CategoricalQNetwork(\n",
    "    observation_spec,\n",
    "    action_spec,\n",
    "    num_atoms=num_atoms,\n",
    "    fc_layer_params=fc_layer_params)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    agent = agents.categorical_dqn.categorical_dqn_agent.CategoricalDqnAgent(\n",
    "        time_step_spec,\n",
    "        action_spec,\n",
    "        categorical_q_network=q_net,\n",
    "        optimizer=optimizer,\n",
    "        td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "        train_step_counter = train_step_counter,\n",
    "        min_q_value = -q_value,\n",
    "        max_q_value = q_value,\n",
    "        n_step_update = n_step_update,\n",
    "        boltzmann_temperature=boltzmann_temperature,\n",
    "        epsilon_greedy=epsilon_greedy,\n",
    "        debug_summaries=debug_summaries,\n",
    "        summarize_grads_and_vars=summarize_grads_and_vars,\n",
    "    )\n",
    "    agent.initialize()\n",
    "    \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03f1bc42-37e4-42c5-9af9-d1124dd4dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.environments.wrappers import PyEnvironmentBaseWrapper\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "class RewardRecordWrapper(PyEnvironmentBaseWrapper):\n",
    "    \"\"\"Clips reward to values of -1, 0, 1 and stores both.\"\"\"\n",
    "\n",
    "    def __init__(self, env: py_environment.PyEnvironment):\n",
    "        \"\"\"Creates a reward clip wrapper.\n",
    "        Args:\n",
    "        env: Environment to wrap.\n",
    "        \"\"\"\n",
    "        super(RewardRecordWrapper, self).__init__(env)\n",
    "\n",
    "        self.reward = []\n",
    "        self.clipped_reward = []\n",
    "\n",
    "    def _step(self, action):\n",
    "\n",
    "        time_step = self._env.step(action)\n",
    "        if not isinstance(time_step, tuple):\n",
    "            done = time_step[2]\n",
    "            if isinstance(time_step[-1], dict) and time_step[-1].get('time_remaining'):\n",
    "                if time_step[-1].get('time_remaining') > 0:\n",
    "                    step_type = StepType.MID\n",
    "                elif time_step[-1].get('time_remaining') == 0 or done:\n",
    "                    step_type = StepType.LAST\n",
    "                else:\n",
    "                    step_type = StepType.MID\n",
    "            else:\n",
    "                step_type = StepType.MID\n",
    "            reward = tf.convert_to_tensor(time_step[1])\n",
    "            discount = tf.convert_to_tensor(1.0)\n",
    "            observation = time_step[0]\n",
    "            meta = time_step[-1]\n",
    "        else:\n",
    "            step_type = time_step.step_type\n",
    "            reward = time_step.reward\n",
    "            discount = time_step.discount\n",
    "            observation = time_step.observation\n",
    "        self.reward.append(reward)\n",
    "\n",
    "        return ts.TimeStep(\n",
    "            step_type,\n",
    "            reward,\n",
    "            discount,\n",
    "            observation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28c4843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.environments import suite_pybullet\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "start_env = suite_pybullet.load(\n",
    "            'Alien-v0')\n",
    "end_env = suite_pybullet.load(\n",
    "            'BankHeist-v0')\n",
    "train_env = tf_py_environment.TFPyEnvironment(start_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(start_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3571429-f847-4f6d-a701-4b3cc5c84961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundedTensorSpec(shape=(210, 160, 3), dtype=tf.uint8, name='observation', minimum=array(0, dtype=uint8), maximum=array(255, dtype=uint8)) BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(17))\n",
      "BoundedArraySpec(shape=(210, 160, 3), dtype=dtype('uint8'), name='observation', minimum=0, maximum=255) BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=17)\n"
     ]
    }
   ],
   "source": [
    "print(train_env.observation_spec(), train_env.action_spec())\n",
    "print(end_env.observation_spec(), end_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "965e8d31",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"queue_memory\" (type QueueMemory).\n\nin user code:\n\n    File \"/home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages/OSAR/queue_memory.py\", line 128, in None  *\n        lambda st: self._update(st, maximum_route, rewards)\n    File \"/home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages/OSAR/queue_memory.py\", line 135, in _update  *\n        compatability_levels_by_queue = self._compute_compatability(\n    File \"/home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages/OSAR/queue_memory.py\", line 99, in _compute_compatability  *\n        logit_substract = tf.tile(\n\n    InvalidArgumentError: Expected multiples argument to be a vector of length 1 but got length 2 [Op:Tile]\n\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(1, 24, 29), dtype=float32)', 'None']\n  • frozen=3\n  • kwargs={'training': 'False'}\n  In call to configurable 'DQNTrialAgent' (<class 'OSAR.agent.DQNTrialAgent'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2113/701235620.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mosar_specs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action_spec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mosar_specs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_step_spec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosar_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mosar_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2113/719084463.py\u001b[0m in \u001b[0;36mosar_generator\u001b[0;34m(observation_spec, action_spec, batch_size, memory_len, n_turns, fc_layer_params, num_atoms, conv_type, learning_rate, time_step_spec, n_step_update, train_step_counter, q_value, boltzmann_temperature, epsilon_greedy, debug_summaries, summarize_grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     agent = DQNTrialAgent(\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mtime_step_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0maction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mscope_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" in scope '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscope_str\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_or_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m       \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_exception_message_and_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgin_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/gin/utils.py\u001b[0m in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExceptionProxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mExceptionProxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/OSAR/agent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, time_step_spec, action_spec, network, optimizer, observation_and_action_constraint_splitter, exploration_noise_std, update_period, td_errors_loss_fn, gamma, batch_size, epsilon_greedy, n_step_update, boltzmann_temperature, emit_log_probability, reward_scale_factor, gradient_clipping, debug_summaries, summarize_grads_and_vars, train_step_counter, name)\u001b[0m\n\u001b[1;32m    162\u001b[0m             net_observation_spec, _ = observation_and_action_constraint_splitter(\n\u001b[1;32m    163\u001b[0m                 net_observation_spec)\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_observation_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/tf_agents/networks/network.py\u001b[0m in \u001b[0;36mcreate_variables\u001b[0;34m(self, input_tensor_spec, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mstep_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFIRST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     outputs = self.__call__(\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mrandom_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mstep_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/tf_agents/networks/network.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m       \u001b[0mnormalized_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"network_state\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnormalized_kwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error  # typed-keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     nest_utils.assert_matching_dtypes_and_inner_shapes(\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/OSAR/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, observation, reward, step_type, network_state, training)\u001b[0m\n\u001b[1;32m    214\u001b[0m              reward], axis=-1)\n\u001b[1;32m    215\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_updated\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/OSAR/sympathetic_circuit.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, frozen)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mmax_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_max_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_space\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         importance = tf.tile(\n\u001b[1;32m    159\u001b[0m             importance, (batch_dim, timesteps_dim, 1))\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/OSAR/queue_memory.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, frozen, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_route\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_route\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"queue_memory\" (type QueueMemory).\n\nin user code:\n\n    File \"/home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages/OSAR/queue_memory.py\", line 128, in None  *\n        lambda st: self._update(st, maximum_route, rewards)\n    File \"/home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages/OSAR/queue_memory.py\", line 135, in _update  *\n        compatability_levels_by_queue = self._compute_compatability(\n    File \"/home/constantine/miniconda3/envs/agents/lib/python3.9/site-packages/OSAR/queue_memory.py\", line 99, in _compute_compatability  *\n        logit_substract = tf.tile(\n\n    InvalidArgumentError: Expected multiples argument to be a vector of length 1 but got length 2 [Op:Tile]\n\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(1, 24, 29), dtype=float32)', 'None']\n  • frozen=3\n  • kwargs={'training': 'False'}\n  In call to configurable 'DQNTrialAgent' (<class 'OSAR.agent.DQNTrialAgent'>)"
     ]
    }
   ],
   "source": [
    "# Phase One: training agent to solve the first game\n",
    "osar_specs['train_step_counter'] = tf.Variable(0, dtype=tf.int64)\n",
    "osar_specs['observation_spec'] = train_env.observation_spec()\n",
    "osar_specs['action_spec'] = train_env.action_spec()\n",
    "osar_specs['time_step_spec'] = train_env.time_step_spec()\n",
    "agent = osar_generator(**osar_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b237e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "c51_specs['train_step_counter'] = tf.Variable(0, dtype=tf.int64)\n",
    "c51_specs['observation_spec'] = train_env.observation_spec()\n",
    "c51_specs['action_spec'] = train_env.action_spec()\n",
    "c51_specs['time_step_spec'] = start_env.time_step_spec()\n",
    "agent = c51_generator(**c51_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e98d1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "\n",
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)\n",
    "\n",
    "# Please also see the metrics module for standard implementations of different\n",
    "# metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f96a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)\n",
    "\n",
    "def collect_step(environment, policy):\n",
    "    time_step = environment.current_time_step()\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step.action)\n",
    "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "    # Add trajectory to the replay buffer\n",
    "    replay_buffer.add_batch(traj)\n",
    "\n",
    "for _ in range(initial_collect_steps):\n",
    "    collect_step(train_env, random_policy)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations of\n",
    "# these. For more details see the drivers module.\n",
    "\n",
    "# Dataset generates trajectories with shape [BxTx...] where\n",
    "# T = n_step_update + 1.\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, sample_batch_size=batch_size,\n",
    "    num_steps=n_step_update + 1).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "926df602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 10000: 100%|████████████████████████████| 10000/10000 [39:14<00:00,  4.25it/s, avg_return=0, train_loss=0.00425]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "try:\n",
    "    %%time\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "with tqdm.trange(num_iterations) as t:\n",
    "    for n_iter in t:\n",
    "\n",
    "        if n_iter == num_iterations // 2:\n",
    "            train_env = tf_py_environment.TFPyEnvironment(end_env)\n",
    "            eval_env = tf_py_environment.TFPyEnvironment(end_env)\n",
    "\n",
    "        # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "        for _ in range(collect_steps_per_iteration):\n",
    "            collect_step(train_env, agent.collect_policy)\n",
    "\n",
    "        # Sample a batch of data from the buffer and update the agent's network.\n",
    "        experience, unused_info = next(iterator)\n",
    "\n",
    "        train_loss = agent.train(experience)\n",
    "\n",
    "        step = agent.train_step_counter.numpy()\n",
    "        t.set_description(f'Episode {step}')\n",
    "#         if step % log_interval == 0:\n",
    "#             print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "        if step % eval_interval == 0:\n",
    "            avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "#             print('step = {0}: Average Return = {1:.2f}'.format(step, avg_return))\n",
    "        t.set_postfix(\n",
    "            train_loss=train_loss.loss.numpy(), avg_return=avg_return)\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1c28eee-297a-452c-9ce6-bdbcb957a0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9.4, 550.0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Step')\n",
    "plt.ylim(top=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fcf853e5-5ddf-4ba9-ac8e-a6f63c3a156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_mp4(filename):\n",
    "      \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "      video = open(filename,'rb').read()\n",
    "      b64 = base64.b64encode(video)\n",
    "      tag = '''\n",
    "      <video width=\"640\" height=\"480\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "      Your browser does not support the video tag.\n",
    "      </video>'''.format(b64.decode())\n",
    "\n",
    "      return IPython.display.HTML(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69238c9d-6f9d-46bd-bcd9-3399907e778f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_980/525961546.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set up a virtual display for rendering OpenAI gym environments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyvirtualdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m900\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvideo_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'imageio.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/pyvirtualdisplay/display.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/pyvirtualdisplay/abstractdisplay.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_displayfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start1_has_displayfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/pyvirtualdisplay/abstractdisplay.py\u001b[0m in \u001b[0;36m_start1_has_displayfd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_pass_fds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_pipe_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_wfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/agents/lib/python3.9/site-packages/pyvirtualdisplay/abstractdisplay.py\u001b[0m in \u001b[0;36m_wait_for_pipe_text\u001b[0;34m(self, rfd)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;31m# start_time = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mrfd_changed_ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrfd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 raise XStartError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up a virtual display for rendering OpenAI gym environments.\n",
    "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
    "    \n",
    "num_episodes = 3\n",
    "video_filename = 'imageio.mp4'\n",
    "with imageio.get_writer(video_filename, fps=60) as video:\n",
    "    for _ in range(num_episodes):\n",
    "        time_step = eval_env.reset()\n",
    "        video.append_data(eval_py_env.render())\n",
    "        frames = 0\n",
    "#         while not time_step.is_last():\n",
    "        if frames < 36000:\n",
    "            action_step = agent.policy.action(time_step)\n",
    "            time_step = eval_env.step(action_step.action)\n",
    "            video.append_data(eval_py_env.render())\n",
    "            frames += 1\n",
    "\n",
    "embed_mp4(video_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe7a71-20d1-4902-9c77-2a81977b62eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e91ad40280a1523fcdfd96f91d1b8381216a30d580c63036f713d86a53d5f08a"
  },
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
